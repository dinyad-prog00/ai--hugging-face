{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget \"https://www.dropbox.com/scl/fi/525gv6tmdi3n32mipo6mr/input.zip?rlkey=5jdsxahphk2ped5wxbxnv0n4y&dl=1\" -O input.zip\n",
    " \n",
    "#!unzip input.zip\n",
    "# https://learnopencv.com/fine-tuning-t5/#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 17:43:26.024549: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-08 17:43:26.053475: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-08 17:43:26.724466: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    " \n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from datasets import load_dataset\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'google-t5/t5-small'\n",
    "BATCH_SIZE =  2 #48\n",
    "NUM_PROCS = 16\n",
    "EPOCHS = 5\n",
    "OUT_DIR = 't5-small-tag-gen'\n",
    "MAX_LENGTH = 256 # Maximum context length to consider while preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = load_dataset(\n",
    "    'csv',\n",
    "    data_files='input/train.csv',\n",
    "    split='train'\n",
    ")\n",
    "dataset_valid = load_dataset(\n",
    "    'csv',\n",
    "    data_files='input/valid.csv',\n",
    "    split='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.info.features\n",
    "dataset_train.info.splits[\"train\"].num_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Id': 34552656,\n",
       " 'Title': 'Java: Repeat Task Every Random Seconds',\n",
       " 'Body': '<p>I\\'m already familiar with repeating tasks every n seconds by using Java.util.Timer and Java.util.TimerTask. But lets say I want to print \"Hello World\" to the console every random seconds from 1-5. Unfortunately I\\'m in a bit of a rush and don\\'t have any code to show so far. Any help would be apriciated.  </p>\\n',\n",
       " 'Tags': '<java><repeat>',\n",
       " 'CreationDate': '2016-01-01 00:21:59',\n",
       " 'Y': 'LQ_CLOSE'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = dataset_train.take(1)\n",
    "ex=next(iter(examples))\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "# Function to convert text data into model inputs and targets\n",
    "def preprocess_function(examples):\n",
    "    inputs = [f\"assign tag: {title} {body}\" for (title, body) in zip(examples['Title'], examples['Body'])]\n",
    "    print(inputs)\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    # Set up the tokenizer for targets\n",
    "    cleaned_tag = [' '.join(''.join(tag.split('<')).split('>')[:-1]) for tag in examples['Tags']]\n",
    "   \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            cleaned_tag,\n",
    "            max_length=MAX_LENGTH,\n",
    "            truncation=True,\n",
    "            padding='max_length'\n",
    "        )\n",
    " \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['assign tag: Java: Repeat Task Every Random Seconds <p>I\\'m already familiar with repeating tasks every n seconds by using Java.util.Timer and Java.util.TimerTask. But lets say I want to print \"Hello World\" to the console every random seconds from 1-5. Unfortunately I\\'m in a bit of a rush and don\\'t have any code to show so far. Any help would be apriciated.  </p>\\n']\n",
      "{'input_ids': [[12317, 7860, 10, 10318, 10, 20469, 16107, 2181, 25942, 5212, 7, 3, 2, 102, 3155, 196, 31, 51, 641, 3324, 28, 6103, 53, 4145, 334, 3, 29, 3978, 57, 338, 10318, 5, 13780, 5, 13368, 52, 11, 10318, 5, 13780, 5, 13368, 52, 382, 9, 7, 157, 5, 299, 8857, 497, 27, 241, 12, 2281, 96, 566, 7126, 1150, 121, 12, 8, 8990, 334, 6504, 3978, 45, 209, 4525, 5, 4877, 27, 31, 51, 16, 3, 9, 720, 13, 3, 9, 10505, 11, 278, 31, 17, 43, 136, 1081, 12, 504, 78, 623, 5, 2372, 199, 133, 36, 3, 9, 2246, 4915, 1054, 5, 3, 2, 87, 102, 3155, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'labels': [[3, 27578, 6103, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/20015587/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_function(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the whole dataset\n",
    "tokenized_train = dataset_train.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=NUM_PROCS\n",
    ")\n",
    "tokenized_valid = dataset_valid.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=NUM_PROCS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60,506,624 total parameters.\n",
      "60,506,624 training parameters.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)\n",
    "# Total parameters and trainable parameters.\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/20015587/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUT_DIR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=OUT_DIR,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='steps',\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=5,\n",
    "    report_to='tensorboard',\n",
    "    learning_rate=0.0001,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=4\n",
    ")\n",
    " \n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bcd75e7ddf49719679addba6ecff85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 23.8884, 'grad_norm': 143.89828491210938, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}\n",
      "{'loss': 23.2158, 'grad_norm': nan, 'learning_rate': 2.6e-06, 'epoch': 0.0}\n",
      "{'loss': 22.3071, 'grad_norm': 115.59175109863281, 'learning_rate': 4.6e-06, 'epoch': 0.0}\n",
      "{'loss': 21.5628, 'grad_norm': 216.89859008789062, 'learning_rate': 6.6e-06, 'epoch': 0.0}\n",
      "{'loss': 20.4574, 'grad_norm': 290.817138671875, 'learning_rate': 8.599999999999999e-06, 'epoch': 0.0}\n",
      "{'loss': 18.6055, 'grad_norm': 327.2432861328125, 'learning_rate': 1.06e-05, 'epoch': 0.0}\n",
      "{'loss': 17.2848, 'grad_norm': 124.83826446533203, 'learning_rate': 1.2600000000000001e-05, 'epoch': 0.0}\n",
      "{'loss': 15.1248, 'grad_norm': 158.93531799316406, 'learning_rate': 1.4599999999999999e-05, 'epoch': 0.0}\n",
      "{'loss': 12.3172, 'grad_norm': 93.06366729736328, 'learning_rate': 1.66e-05, 'epoch': 0.0}\n",
      "{'loss': 9.9199, 'grad_norm': 108.13162994384766, 'learning_rate': 1.86e-05, 'epoch': 0.0}\n",
      "{'loss': 7.6012, 'grad_norm': 103.59687042236328, 'learning_rate': 2.06e-05, 'epoch': 0.0}\n",
      "{'loss': 5.607, 'grad_norm': 145.6820068359375, 'learning_rate': 2.26e-05, 'epoch': 0.01}\n",
      "{'loss': 2.4856, 'grad_norm': 19.08002281188965, 'learning_rate': 2.46e-05, 'epoch': 0.01}\n",
      "{'loss': 1.6067, 'grad_norm': 25.48721694946289, 'learning_rate': 2.6600000000000003e-05, 'epoch': 0.01}\n",
      "{'loss': 0.9773, 'grad_norm': 3.098252534866333, 'learning_rate': 2.86e-05, 'epoch': 0.01}\n",
      "{'loss': 0.5746, 'grad_norm': 2.809849739074707, 'learning_rate': 3.06e-05, 'epoch': 0.01}\n",
      "{'loss': 0.4794, 'grad_norm': 1.4477359056472778, 'learning_rate': 3.26e-05, 'epoch': 0.01}\n",
      "{'loss': 0.3649, 'grad_norm': 2.548917293548584, 'learning_rate': 3.46e-05, 'epoch': 0.01}\n",
      "{'loss': 0.3194, 'grad_norm': 0.924056351184845, 'learning_rate': 3.66e-05, 'epoch': 0.01}\n",
      "{'loss': 0.3228, 'grad_norm': 0.9877381920814514, 'learning_rate': 3.86e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2932, 'grad_norm': 0.9532317519187927, 'learning_rate': 4.0600000000000004e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2286, 'grad_norm': 1.2253227233886719, 'learning_rate': 4.26e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2454, 'grad_norm': 0.926241934299469, 'learning_rate': 4.46e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2105, 'grad_norm': 0.9253700971603394, 'learning_rate': 4.660000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 0.207, 'grad_norm': 1.4260666370391846, 'learning_rate': 4.86e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2556, 'grad_norm': 0.9779422283172607, 'learning_rate': 5.0600000000000003e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2101, 'grad_norm': 0.7124512195587158, 'learning_rate': 5.2600000000000005e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2318, 'grad_norm': 0.4894413948059082, 'learning_rate': 5.4600000000000006e-05, 'epoch': 0.01}\n",
      "{'loss': 0.1899, 'grad_norm': 0.476796954870224, 'learning_rate': 5.66e-05, 'epoch': 0.01}\n",
      "{'loss': 0.1851, 'grad_norm': 0.6754538416862488, 'learning_rate': 5.86e-05, 'epoch': 0.01}\n",
      "{'loss': 0.1687, 'grad_norm': 0.6191434860229492, 'learning_rate': 6.06e-05, 'epoch': 0.01}\n",
      "{'loss': 0.1549, 'grad_norm': 0.5691666007041931, 'learning_rate': 6.26e-05, 'epoch': 0.01}\n",
      "{'loss': 0.1875, 'grad_norm': 0.7502691149711609, 'learning_rate': 6.460000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 0.1621, 'grad_norm': 0.3415151536464691, 'learning_rate': 6.66e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1684, 'grad_norm': 0.49749425053596497, 'learning_rate': 6.860000000000001e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1615, 'grad_norm': 0.6327511668205261, 'learning_rate': 7.06e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1844, 'grad_norm': 1.8649470806121826, 'learning_rate': 7.26e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1926, 'grad_norm': 0.38515734672546387, 'learning_rate': 7.46e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1438, 'grad_norm': 1.741542100906372, 'learning_rate': 7.66e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1673, 'grad_norm': 4.648951530456543, 'learning_rate': 7.860000000000001e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1319, 'grad_norm': 1.2814397811889648, 'learning_rate': 8.060000000000001e-05, 'epoch': 0.02}\n",
      "{'loss': 0.16, 'grad_norm': 0.747050404548645, 'learning_rate': 8.26e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1415, 'grad_norm': 0.4581618010997772, 'learning_rate': 8.46e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1374, 'grad_norm': 0.6421946883201599, 'learning_rate': 8.66e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1366, 'grad_norm': 0.4403279721736908, 'learning_rate': 8.86e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1462, 'grad_norm': 0.9079594612121582, 'learning_rate': 9.06e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1161, 'grad_norm': 0.5718184113502502, 'learning_rate': 9.260000000000001e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1352, 'grad_norm': 13.515588760375977, 'learning_rate': 9.46e-05, 'epoch': 0.02}\n",
      "{'loss': 0.0995, 'grad_norm': 0.5409776568412781, 'learning_rate': 9.66e-05, 'epoch': 0.02}\n",
      "{'loss': 0.0973, 'grad_norm': 3.9379100799560547, 'learning_rate': 9.86e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4768d2db72a4b49999150784f9d7c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10462861508131027, 'eval_runtime': 2021.6771, 'eval_samples_per_second': 7.42, 'eval_steps_per_second': 3.71, 'epoch': 0.02}\n",
      "{'loss': 0.1029, 'grad_norm': 0.5681705474853516, 'learning_rate': 9.999732142857143e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1134, 'grad_norm': 0.6650452613830566, 'learning_rate': 9.998839285714286e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1388, 'grad_norm': 0.7985198497772217, 'learning_rate': 9.997946428571428e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1025, 'grad_norm': 0.5626926422119141, 'learning_rate': 9.997053571428572e-05, 'epoch': 0.02}\n",
      "{'loss': 0.099, 'grad_norm': 0.7779288291931152, 'learning_rate': 9.996160714285715e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1204, 'grad_norm': 0.3318697214126587, 'learning_rate': 9.995267857142857e-05, 'epoch': 0.02}\n",
      "{'loss': 0.106, 'grad_norm': 0.7802842259407043, 'learning_rate': 9.994375e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1116, 'grad_norm': 1.209157943725586, 'learning_rate': 9.993482142857144e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0846, 'grad_norm': 0.3906325101852417, 'learning_rate': 9.992589285714286e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0989, 'grad_norm': 0.48132047057151794, 'learning_rate': 9.991696428571429e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1255, 'grad_norm': 0.34916025400161743, 'learning_rate': 9.990803571428572e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1269, 'grad_norm': 0.34757664799690247, 'learning_rate': 9.989910714285715e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0929, 'grad_norm': 0.7528143525123596, 'learning_rate': 9.989017857142857e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0872, 'grad_norm': 0.47699782252311707, 'learning_rate': 9.988125e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0875, 'grad_norm': 0.3012893497943878, 'learning_rate': 9.987232142857143e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0787, 'grad_norm': 0.8056047558784485, 'learning_rate': 9.986339285714286e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0914, 'grad_norm': 0.3674178123474121, 'learning_rate': 9.98544642857143e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1046, 'grad_norm': 0.32263660430908203, 'learning_rate': 9.984553571428572e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0957, 'grad_norm': 0.33033061027526855, 'learning_rate': 9.983660714285715e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0912, 'grad_norm': 0.32360929250717163, 'learning_rate': 9.982767857142857e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1181, 'grad_norm': 2.574150323867798, 'learning_rate': 9.981875000000001e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0907, 'grad_norm': 0.4103728234767914, 'learning_rate': 9.980982142857144e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0754, 'grad_norm': 0.3760261535644531, 'learning_rate': 9.980089285714286e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1184, 'grad_norm': 0.3571242094039917, 'learning_rate': 9.979196428571429e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0763, 'grad_norm': 0.42831990122795105, 'learning_rate': 9.978303571428573e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1322, 'grad_norm': 0.4485689401626587, 'learning_rate': 9.977410714285714e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1113, 'grad_norm': 0.18071264028549194, 'learning_rate': 9.976517857142858e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0952, 'grad_norm': 0.606714129447937, 'learning_rate': 9.975625e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1054, 'grad_norm': 0.4635828137397766, 'learning_rate': 9.974732142857144e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1053, 'grad_norm': 1.4871811866760254, 'learning_rate': 9.973839285714285e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0943, 'grad_norm': 0.3963765799999237, 'learning_rate': 9.972946428571429e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0971, 'grad_norm': 0.4405776262283325, 'learning_rate': 9.972053571428572e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0954, 'grad_norm': 0.3578052222728729, 'learning_rate': 9.971160714285714e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1037, 'grad_norm': 0.21268419921398163, 'learning_rate': 9.970267857142858e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1393, 'grad_norm': 0.5140935182571411, 'learning_rate': 9.969375000000001e-05, 'epoch': 0.04}\n",
      "{'loss': 0.102, 'grad_norm': 0.2052302211523056, 'learning_rate': 9.968482142857143e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0989, 'grad_norm': 0.36873605847358704, 'learning_rate': 9.967589285714286e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0853, 'grad_norm': 0.20707248151302338, 'learning_rate': 9.96669642857143e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0767, 'grad_norm': 0.4841099679470062, 'learning_rate': 9.965803571428572e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1057, 'grad_norm': 0.2845052182674408, 'learning_rate': 9.964910714285715e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0993, 'grad_norm': 0.16702252626419067, 'learning_rate': 9.964017857142857e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0867, 'grad_norm': 0.32876789569854736, 'learning_rate': 9.963125000000001e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0708, 'grad_norm': 1.1716129779815674, 'learning_rate': 9.962232142857142e-05, 'epoch': 0.04}\n",
      "{'loss': 0.094, 'grad_norm': 0.38875147700309753, 'learning_rate': 9.961339285714286e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0854, 'grad_norm': 0.17744475603103638, 'learning_rate': 9.960446428571429e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0919, 'grad_norm': 0.38537514209747314, 'learning_rate': 9.959553571428571e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1016, 'grad_norm': 1.2353283166885376, 'learning_rate': 9.958660714285714e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0848, 'grad_norm': 0.33256450295448303, 'learning_rate': 9.957767857142858e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1307, 'grad_norm': 0.522142231464386, 'learning_rate': 9.956875e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0822, 'grad_norm': 0.34433645009994507, 'learning_rate': 9.955982142857143e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1fda7198614d87bb5c4eeaa1a1dc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08427439630031586, 'eval_runtime': 2021.7456, 'eval_samples_per_second': 7.419, 'eval_steps_per_second': 3.71, 'epoch': 0.04}\n",
      "{'loss': 0.0702, 'grad_norm': 0.22672660648822784, 'learning_rate': 9.955089285714287e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0847, 'grad_norm': 4.943324089050293, 'learning_rate': 9.95419642857143e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0862, 'grad_norm': 0.2861299216747284, 'learning_rate': 9.953303571428572e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1101, 'grad_norm': 0.2224818766117096, 'learning_rate': 9.952410714285715e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0858, 'grad_norm': 1.0967695713043213, 'learning_rate': 9.951517857142858e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1047, 'grad_norm': 0.14748026430606842, 'learning_rate': 9.950625e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0915, 'grad_norm': 0.37190258502960205, 'learning_rate': 9.949732142857144e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0883, 'grad_norm': 0.2634839415550232, 'learning_rate': 9.948839285714286e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1024, 'grad_norm': 0.3275047540664673, 'learning_rate': 9.947946428571429e-05, 'epoch': 0.05}\n",
      "{'loss': 0.072, 'grad_norm': 0.3108656704425812, 'learning_rate': 9.947053571428571e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1066, 'grad_norm': 0.38791367411613464, 'learning_rate': 9.946160714285715e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1249, 'grad_norm': 0.18657556176185608, 'learning_rate': 9.945267857142858e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0924, 'grad_norm': 0.21285001933574677, 'learning_rate': 9.944375e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0729, 'grad_norm': 0.15749362111091614, 'learning_rate': 9.943482142857144e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0828, 'grad_norm': 0.44677361845970154, 'learning_rate': 9.942589285714287e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0998, 'grad_norm': 0.2711109519004822, 'learning_rate': 9.941696428571429e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0953, 'grad_norm': 0.4222779870033264, 'learning_rate': 9.940803571428572e-05, 'epoch': 0.05}\n",
      "{'loss': 0.065, 'grad_norm': 0.29430773854255676, 'learning_rate': 9.939910714285716e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0857, 'grad_norm': 0.1680642068386078, 'learning_rate': 9.939017857142857e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0776, 'grad_norm': 0.5937080383300781, 'learning_rate': 9.938125e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0942, 'grad_norm': 0.28954625129699707, 'learning_rate': 9.937232142857143e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0814, 'grad_norm': 0.5537282824516296, 'learning_rate': 9.936339285714287e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0955, 'grad_norm': 0.4238365590572357, 'learning_rate': 9.935446428571428e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1055, 'grad_norm': 0.3246955871582031, 'learning_rate': 9.934553571428572e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0809, 'grad_norm': 0.4625520706176758, 'learning_rate': 9.933660714285715e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0796, 'grad_norm': 0.48843684792518616, 'learning_rate': 9.932767857142857e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1156, 'grad_norm': 0.5741323232650757, 'learning_rate': 9.931875e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0711, 'grad_norm': 0.380018413066864, 'learning_rate': 9.930982142857144e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0931, 'grad_norm': 0.4716479778289795, 'learning_rate': 9.930089285714286e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0772, 'grad_norm': 0.334519624710083, 'learning_rate': 9.929196428571429e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0751, 'grad_norm': 0.41352203488349915, 'learning_rate': 9.928303571428573e-05, 'epoch': 0.06}\n",
      "{'loss': 0.078, 'grad_norm': 0.15483243763446808, 'learning_rate': 9.927410714285714e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0664, 'grad_norm': 0.3894518315792084, 'learning_rate': 9.926517857142858e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0964, 'grad_norm': 0.3615223467350006, 'learning_rate': 9.925625e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0969, 'grad_norm': 0.3437840938568115, 'learning_rate': 9.924732142857144e-05, 'epoch': 0.06}\n",
      "{'loss': 0.103, 'grad_norm': 0.4958460032939911, 'learning_rate': 9.923839285714285e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1007, 'grad_norm': 0.2161388397216797, 'learning_rate': 9.92294642857143e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0731, 'grad_norm': 0.37535107135772705, 'learning_rate': 9.922053571428572e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0968, 'grad_norm': 0.3279019296169281, 'learning_rate': 9.921160714285714e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0793, 'grad_norm': 0.15568336844444275, 'learning_rate': 9.920267857142857e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0791, 'grad_norm': 0.44176599383354187, 'learning_rate': 9.919375000000001e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1004, 'grad_norm': 0.6958877444267273, 'learning_rate': 9.918482142857143e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0891, 'grad_norm': 0.43874579668045044, 'learning_rate': 9.917589285714286e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0971, 'grad_norm': 0.8997718095779419, 'learning_rate': 9.91669642857143e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1048, 'grad_norm': 0.19350355863571167, 'learning_rate': 9.915803571428572e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0831, 'grad_norm': 0.2991526126861572, 'learning_rate': 9.914910714285715e-05, 'epoch': 0.06}\n",
      "{'loss': 0.101, 'grad_norm': 0.33696919679641724, 'learning_rate': 9.914017857142858e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0818, 'grad_norm': 0.36693108081817627, 'learning_rate': 9.913125000000001e-05, 'epoch': 0.07}\n",
      "{'loss': 0.082, 'grad_norm': 0.3759271800518036, 'learning_rate': 9.912232142857143e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0731, 'grad_norm': 0.26124364137649536, 'learning_rate': 9.911339285714287e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34cd8eae83c49719ff35b77d0a349b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07876913994550705, 'eval_runtime': 2021.6934, 'eval_samples_per_second': 7.42, 'eval_steps_per_second': 3.71, 'epoch': 0.07}\n",
      "{'loss': 0.0922, 'grad_norm': 0.28160831332206726, 'learning_rate': 9.910446428571429e-05, 'epoch': 0.07}\n",
      "{'loss': 0.1038, 'grad_norm': 0.4383435547351837, 'learning_rate': 9.909553571428572e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0948, 'grad_norm': 0.28863248229026794, 'learning_rate': 9.908660714285714e-05, 'epoch': 0.07}\n",
      "{'loss': 0.1246, 'grad_norm': 0.6986559629440308, 'learning_rate': 9.907767857142858e-05, 'epoch': 0.07}\n",
      "{'loss': 0.085, 'grad_norm': 0.4569411277770996, 'learning_rate': 9.906875e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0594, 'grad_norm': 0.2801000773906708, 'learning_rate': 9.905982142857143e-05, 'epoch': 0.07}\n",
      "{'loss': 0.076, 'grad_norm': 0.23465761542320251, 'learning_rate': 9.905089285714286e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0946, 'grad_norm': 0.48102355003356934, 'learning_rate': 9.90419642857143e-05, 'epoch': 0.07}\n",
      "{'loss': 0.1149, 'grad_norm': 0.5222657322883606, 'learning_rate': 9.903303571428572e-05, 'epoch': 0.07}\n",
      "{'loss': 0.072, 'grad_norm': 2.446577787399292, 'learning_rate': 9.902410714285715e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0667, 'grad_norm': 0.5722739100456238, 'learning_rate': 9.901517857142859e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0771, 'grad_norm': 0.351963609457016, 'learning_rate': 9.900625e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0922, 'grad_norm': 0.3322746753692627, 'learning_rate': 9.899732142857144e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0686, 'grad_norm': 0.10936937481164932, 'learning_rate': 9.898839285714286e-05, 'epoch': 0.07}\n",
      "{'loss': 0.097, 'grad_norm': 0.47701263427734375, 'learning_rate': 9.897946428571429e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0946, 'grad_norm': 0.2291073352098465, 'learning_rate': 9.897053571428571e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0846, 'grad_norm': 0.695164144039154, 'learning_rate': 9.896160714285715e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0683, 'grad_norm': 0.39456072449684143, 'learning_rate': 9.895267857142858e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0731, 'grad_norm': 0.36742788553237915, 'learning_rate': 9.894375e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0886, 'grad_norm': 0.15389668941497803, 'learning_rate': 9.893482142857143e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0855, 'grad_norm': 0.3172815144062042, 'learning_rate': 9.892589285714287e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0769, 'grad_norm': 0.43626582622528076, 'learning_rate': 9.891696428571429e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0976, 'grad_norm': 0.7141234278678894, 'learning_rate': 9.890803571428572e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0717, 'grad_norm': 0.38043639063835144, 'learning_rate': 9.889910714285714e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0746, 'grad_norm': 0.2795273959636688, 'learning_rate': 9.889017857142857e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0756, 'grad_norm': 0.2801333963871002, 'learning_rate': 9.888125000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 0.092, 'grad_norm': 0.30208927392959595, 'learning_rate': 9.887232142857143e-05, 'epoch': 0.08}\n",
      "{'loss': 0.1045, 'grad_norm': 0.32447823882102966, 'learning_rate': 9.886339285714287e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0846, 'grad_norm': 0.28318482637405396, 'learning_rate': 9.885446428571428e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0776, 'grad_norm': 0.27723193168640137, 'learning_rate': 9.884553571428572e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0765, 'grad_norm': 0.2419266402721405, 'learning_rate': 9.883660714285715e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0797, 'grad_norm': 0.2259189784526825, 'learning_rate': 9.882767857142857e-05, 'epoch': 0.08}\n",
      "{'loss': 0.1108, 'grad_norm': 0.4523944556713104, 'learning_rate': 9.881875e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0793, 'grad_norm': 0.3184582591056824, 'learning_rate': 9.880982142857144e-05, 'epoch': 0.08}\n",
      "{'loss': 0.1018, 'grad_norm': 0.1524464339017868, 'learning_rate': 9.880089285714285e-05, 'epoch': 0.08}\n",
      "{'loss': 0.1012, 'grad_norm': 0.2993937134742737, 'learning_rate': 9.879196428571429e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0711, 'grad_norm': 0.4543097913265228, 'learning_rate': 9.878303571428572e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0872, 'grad_norm': 0.3010620176792145, 'learning_rate': 9.877410714285715e-05, 'epoch': 0.08}\n",
      "{'loss': 0.08, 'grad_norm': 0.1522682160139084, 'learning_rate': 9.876517857142858e-05, 'epoch': 0.08}\n",
      "{'loss': 0.1013, 'grad_norm': 0.23137249052524567, 'learning_rate': 9.875625e-05, 'epoch': 0.08}\n",
      "{'loss': 0.106, 'grad_norm': 0.283348023891449, 'learning_rate': 9.874732142857144e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0777, 'grad_norm': 0.3494478166103363, 'learning_rate': 9.873839285714286e-05, 'epoch': 0.09}\n",
      "{'loss': 0.1018, 'grad_norm': 0.4185994565486908, 'learning_rate': 9.87294642857143e-05, 'epoch': 0.09}\n",
      "{'loss': 0.087, 'grad_norm': 0.43625402450561523, 'learning_rate': 9.872053571428572e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0584, 'grad_norm': 0.3990461230278015, 'learning_rate': 9.871160714285715e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0832, 'grad_norm': 0.5768827199935913, 'learning_rate': 9.870267857142857e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0711, 'grad_norm': 0.26859423518180847, 'learning_rate': 9.869375000000001e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0939, 'grad_norm': 0.3370171785354614, 'learning_rate': 9.868482142857142e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0776, 'grad_norm': 0.34701037406921387, 'learning_rate': 9.867589285714286e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0951, 'grad_norm': 0.4428175985813141, 'learning_rate': 9.866696428571429e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8901ed0b64a5480d956261d59e30593d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/transformers/trainer.py:2291\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2291\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/transformers/trainer.py:2721\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2719\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2721\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2722\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2724\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/transformers/trainer.py:3572\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3569\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3571\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3572\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3573\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3575\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3576\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3582\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/transformers/trainer.py:3747\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3744\u001b[0m observed_num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3746\u001b[0m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[0;32m-> 3747\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m   3748\u001b[0m     \u001b[38;5;66;03m# Update the observed num examples\u001b[39;00m\n\u001b[1;32m   3749\u001b[0m     observed_batch_size \u001b[38;5;241m=\u001b[39m find_batch_size(inputs)\n\u001b[1;32m   3750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m observed_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/accelerate/data_loader.py:463\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/accelerate/utils/operations.py:186\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[0;32m--> 186\u001b[0m         {\n\u001b[1;32m    187\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m send_to_device(t, device, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking, skip_keys\u001b[38;5;241m=\u001b[39mskip_keys)\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    189\u001b[0m         }\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/accelerate/utils/operations.py:187\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[1;32m    186\u001b[0m         {\n\u001b[0;32m--> 187\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    189\u001b[0m         }\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/accelerate/utils/operations.py:158\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    156\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t5-small-tag-gen/tokenizer_config.json',\n",
       " 't5-small-tag-gen/special_tokens_map.json',\n",
       " 't5-small-tag-gen/spiece.model',\n",
       " 't5-small-tag-gen/added_tokens.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "model_path = 't5-small-tag-gen/checkpoint-1500'  # the path where you saved your model\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small-tag-gen')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\t\n",
    "def do_correction(text, model, tokenizer):\n",
    "    input_text = f\"assign tag: {text}\"\n",
    "    inputs = tokenizer.encode(\n",
    "        input_text,\n",
    "        return_tensors='pt',\n",
    "        max_length=256,\n",
    "        padding='max_length',\n",
    "        truncation=True\n",
    "    )\n",
    " \n",
    "    # Get correct sentence ids.\n",
    "    corrected_ids = model.generate(\n",
    "        inputs,\n",
    "        max_length=256,\n",
    "        num_beams=5, # `num_beams=1` indicated temperature sampling.\n",
    "        early_stopping=True\n",
    "    )\n",
    " \n",
    "    # Decode.\n",
    "    corrected_sentence = tokenizer.decode(\n",
    "        corrected_ids[0],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    return corrected_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sql-server'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_correction(\"\"\"\n",
    "              How to get all the child records from different tables based on given parent ID in sql server,\"I am having 4 different tables like \n",
    "select * from System \n",
    " \n",
    "select * from Set \n",
    "select * from Item \n",
    "select * from Versions \n",
    "\n",
    "Now for each system Id there will be **n no.of Sets**, and foe **each set** there qill be **n no. of Items** and for **each item** there will be **n no.of Versions**.\n",
    "\n",
    "**each system has  <br/>\n",
    "n no of set <br/>\n",
    "each Set has <br/>\n",
    "n no of Items <br/>\n",
    "each Item has <br/>\n",
    "n no of Versions**\n",
    "\n",
    "\n",
    "So, Now when i give **SystemId** then i have to retrieve all the records from \n",
    "\n",
    "**Set and Items of each set and Versions of each Items** in single storedprocedure.\"\n",
    "              \n",
    "              \"\"\",model,tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
